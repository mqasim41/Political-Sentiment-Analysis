{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch ijson\n",
    "%pip install openai\n",
    "%pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Download koo post data from drive and extract it to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "import zipfile\n",
    "def download_file(source, download_dir, )-> str:\n",
    "    '''\n",
    "    Fetch data from the url\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        dataset_url = source\n",
    "        zip_download_dir = download_dir\n",
    "        os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "\n",
    "\n",
    "        file_id = dataset_url.split(\"/\")[-2]\n",
    "        prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "        gdown.download(prefix+file_id,zip_download_dir)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "def extract_zip_file(unzip_dir, data_file):\n",
    "    \"\"\"\n",
    "    zip_file_path: str\n",
    "    Extracts the zip file into the data directory\n",
    "    Function returns None\n",
    "    \"\"\"\n",
    "    unzip_path = unzip_dir\n",
    "    os.makedirs(unzip_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(data_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Function to download the labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "def download_json():\n",
    "\n",
    "  # Download the file to your local machine\n",
    "  files.download('labelled_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function prompts the gpt-4o mini model to classify each post into political/non-political. For the political posts it then determines their political alignment, what the topic of the post is and the overall sentiment of the post.\n",
    "\n",
    "The topics are limited to the following:\n",
    "\n",
    "  1. Government Schemes and Initiatives\n",
    "  2. Political Campaigns and Rallies\n",
    "  3. Statements and Speeches by Politicians\n",
    "  4. Social and Cultural Issues\n",
    "  5. Economic Policies and Reforms\n",
    "  6. Public Reactions and Opinions\n",
    "  7. Development Projects and Infrastructure\n",
    "  8. Law and Order\n",
    "  9. Environmental Policies and Issues\n",
    "  10. Health and Education Policies\n",
    "\n",
    "The alignment of the post is determined through the following criteria:\n",
    "\"Left-Wing Politics: Communist Party of India (CPI), Communist Party of India (Marxist) (CPI(M)), Communist Party of India (Marxist–Leninist) Liberation (CPI(ML) Liberation), All India Forward Bloc (AIFB), Revolutionary Socialist Party (RSP)\n",
    "\n",
    "Centrist Politics: Indian National Congress (INC), Nationalist Congress Party (NCP), Aam Aadmi Party (AAP), Biju Janata Dal (BJD), Telangana Rashtra Samithi (TRS), Dravida Munnetra Kazhagam (DMK), Yuvajana Sramika Rythu Congress Party (YSRCP)\n",
    "\n",
    "Right-Wing Politics: Bharatiya Janata Party (BJP), Shiv Sena, Akhil Bharatiya Hindu Mahasabha, Rashtriya Swayamsevak Sangh (RSS) (Note: RSS is not a political party but has significant influence on the BJP), Shiromani Akali Dal (SAD)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def classify_post(post, API_KEY, API_URL):\n",
    "    # Create the prompt for the classification\n",
    "    prompt = f\"\"\"\n",
    "Classify the following post, identify its political alignment, topic, and analyze its sentiment. The post is considered related to politics if it mentions political parties, their members, their performance, or their policies, with politicians limited to those in the Lok Sabha (Lower house of Indian Parliament). If related to politics, classify the political alignment (Right-Wing Politics, Left-Wing Politics, Centrist Politics) in India according to the following classification:\n",
    "\n",
    "Left-Wing Politics: Communist Party of India (CPI), Communist Party of India (Marxist) (CPI(M)), Communist Party of India (Marxist–Leninist) Liberation (CPI(ML) Liberation), All India Forward Bloc (AIFB), Revolutionary Socialist Party (RSP)\n",
    "Centrist Politics: Indian National Congress (INC), Nationalist Congress Party (NCP), Aam Aadmi Party (AAP), Biju Janata Dal (BJD), Telangana Rashtra Samithi (TRS), Dravida Munnetra Kazhagam (DMK), Yuvajana Sramika Rythu Congress Party (YSRCP)\n",
    "Right-Wing Politics: Bharatiya Janata Party (BJP), Shiv Sena, Akhil Bharatiya Hindu Mahasabha, Rashtriya Swayamsevak Sangh (RSS) (Note: RSS is not a political party but has significant influence on the BJP), Shiromani Akali Dal (SAD)\n",
    "\n",
    "Post: {post['title']}\n",
    "\n",
    "1. Classification (Related to Politics/Not Related to Politics):\n",
    "2. If related to politics, identify the political alignment (Right-Wing Politics/Left-Wing Politics/Centrist Politics):\n",
    "3. Topic (Choose from the list): Identified Topic:\n",
    "  Topics:\n",
    "  1. Government Schemes and Initiatives\n",
    "  2. Political Campaigns and Rallies\n",
    "  3. Statements and Speeches by Politicians\n",
    "  4. Social and Cultural Issues\n",
    "  5. Economic Policies and Reforms\n",
    "  6. Public Reactions and Opinions\n",
    "  7. Development Projects and Infrastructure\n",
    "  8. Law and Order\n",
    "  9. Environmental Policies and Issues\n",
    "  10. Health and Education Policies\n",
    "\n",
    "4. Sentiment (Positive/Negative/Neutral):\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the request payload\n",
    "    payload = {\n",
    "        'model': 'gpt-4o-mini',\n",
    "        'messages': [{'role': 'user', 'content': prompt}],\n",
    "        'temperature': 0.7\n",
    "    }\n",
    "\n",
    "    # Set the headers\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    # Send the POST request to the OpenAI API\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "    # Check the response status and parse the classification\n",
    "    try:\n",
    "      if response.status_code == 200:\n",
    "        response_content = response.json()['choices'][0]['message']['content'].strip()\n",
    "\n",
    "        # Split the response into lines\n",
    "        lines = response_content.split('\\n')\n",
    "\n",
    "        # Initialize variables to store the extracted values\n",
    "        classification = None\n",
    "        political_alignment = None\n",
    "        topic = None\n",
    "        sentiment = None\n",
    "\n",
    "        # Parse the response content\n",
    "        for line in lines:\n",
    "            if 'Classification' in line:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) > 1:\n",
    "                    classification = parts[1].strip()\n",
    "            elif 'political alignment' in line:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) > 1:\n",
    "                    political_alignment = parts[1].strip()\n",
    "            elif 'Identified Topic' in line:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) > 1:\n",
    "                    topic = parts[2].strip()\n",
    "            elif 'Sentiment' in line:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) > 1:\n",
    "                    sentiment = parts[1].strip()\n",
    "\n",
    "        return classification, political_alignment, topic, sentiment\n",
    "      else:\n",
    "          print(f\"Error: {response.status_code}, {response.text}\")\n",
    "          return None, None, None, None\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error: {e}\")\n",
    "      return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract necessary information from prompt. Only 10000 prompts can be processed at a time due to the usage limit on the api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Replace with your actual OpenAI API key\n",
    "API_KEY = 'INSER YOUR API KEY'\n",
    "API_URL = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "\n",
    "with open('/content/artifacts/data_ingestion/out.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "processed_titles = set()\n",
    "\n",
    "count = 0\n",
    "for post in data:\n",
    "    if post['title'] in processed_titles:\n",
    "        continue  # Skip if the post has already been processed\n",
    "\n",
    "    classification, political_alignment, topic, sentiment = classify_post(post, API_KEY, API_URL)\n",
    "    if classification:\n",
    "        post['classification'] = classification\n",
    "        if classification == 'Related to Politics':\n",
    "            post['political_alignment'] = political_alignment\n",
    "            if topic:\n",
    "                post['topic'] = topic\n",
    "        else:\n",
    "            post['political_alignment'] = 'N/A'\n",
    "        if sentiment:\n",
    "            post['sentiment'] = sentiment\n",
    "        processed_data.append(post)\n",
    "        processed_titles.add(post['title'])\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f\"Processed {count} posts\")\n",
    "            print(processed_data[-10:])\n",
    "\n",
    "        if count == 10000:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Save the processed data to a new JSON file\n",
    "with open('new_out.json', 'w') as file:\n",
    "    json.dump(processed_data, file, indent=4)\n",
    "\n",
    "download_json()\n",
    "\n",
    "print(\"Classification complete and saved to new_out.json\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
